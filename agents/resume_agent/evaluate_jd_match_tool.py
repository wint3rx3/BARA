import json
from llm_client.llm import llm

def run(state: dict) -> dict:
    jd = state.get("jd_structured", {})
    resume = state.get("resume_topics", {})
    result = {}

    jd_summary = json.dumps(jd, ensure_ascii=False)

    for question_raw, content in resume.items():
        question = question_raw.replace("ë³´ê¸°", "").strip()
        attitude = ", ".join(content.get("attitude", []))
        experience = ", ".join(content.get("experience", []))

        prompt = f"""
ë‹¹ì‹ ì€ ìê¸°ì†Œê°œì„œ ì²¨ì‚­ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ì˜ JD ìš”ì•½ê³¼ ìê¸°ì†Œê°œì„œ ìš”ì•½ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìê°€ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•  ë•Œ ì–´ë–¤ ë‚´ìš©ê³¼ ê²½í—˜ì„ ì“°ëŠ” ê²ƒì´ ì¢‹ì€ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì¡°ì–¸í•´ ì£¼ì„¸ìš”.

[JD ìš”ì•½ ì •ë³´]
{jd_summary}

[ìê¸°ì†Œê°œì„œ ìš”ì•½ í‚¤ì›Œë“œ]
- íƒœë„: {attitude}
- ìœ ê´€ê²½í—˜: {experience}

[ìê¸°ì†Œê°œì„œ ë¬¸í•­]
"{question}"

ğŸ“Œ ì‘ì„±ìì—ê²Œ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì§ì ‘ ì¡°ì–¸í•˜ì„¸ìš”:
- ì–´ë–¤ JD í•­ëª©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì“°ë©´ ì¢‹ì€ì§€
- ì–´ë–¤ ê²½í—˜(ì˜ˆ: í”„ë¡œì íŠ¸, í˜‘ì—…, ë¬¸ì œí•´ê²°)ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì„œìˆ í•˜ë©´ ì¢‹ì€ì§€
- ë¬¸ë‹¨ì˜ íë¦„ì´ë‚˜ í‚¤ì›Œë“œ ë°°ì—´ì€ ì–´ë–»ê²Œ í•˜ë©´ ì¢‹ì€ì§€
- "ë¶€í•©í•œë‹¤", "ì˜ ë§ëŠ”ë‹¤" ê°™ì€ ì¶”ìƒì ì¸ í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
- ë…ìê°€ ë°”ë¡œ ì´í•´í•  ìˆ˜ ìˆë„ë¡, êµ¬ì²´ì ì¸ ë¬¸ì¥ ì˜ˆì‹œë‚˜ í‘œí˜„ ë°©ì‹ì„ ì¶”ì²œí•˜ì„¸ìš”

ë§íˆ¬ëŠ” "~í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤." í˜•íƒœì˜ ì¡°ì–¸í˜• ì„œìˆ ë¡œ, ì´ 5~7ë¬¸ì¥ ì´ë‚´ë¡œ êµ¬ì„±í•˜ì„¸ìš”.
"""

        try:
            response = llm.chat.completions.create(
                model="solar-pro",
                messages=[{"role": "user", "content": prompt}]
            )
            result[question] = response.choices[0].message.content.strip()
        except Exception as e:
            result[question] = f"[ì˜¤ë¥˜ ë°œìƒ: {e}]"

    state["jd_alignment"] = result
    return state
